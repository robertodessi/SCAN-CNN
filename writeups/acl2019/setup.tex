\section{SCAN}
\label{sec:setup}

SCAN studies compositionality in the context of a simple command
execution environment framed as a supervised sequence-to-sequence
task. The neural network receives word sequences as input, and has to
produce the correspondence sequence of actions. Some examples are
given in Table \ref{table:examples}.
  \newcite{Lake:Baroni:2017} originally introduced 4
train/test splits, of which we consider here two.\footnote{We also
  tested our CNNs on SCAN's \emph{length} split, where test commands
  require systematically longer actions than the training
  ones. Accuracy was always near 0\%, as the learned positional
  embeddings of the CNN architecture we use does not allow
  generalization beyond lengths observed in training. We leave the
  investigation of more flexible positional encodings \cite[as in,
  e.g.,][]{vaswani:etal:2017} to future work. We also experimented
  with the \emph{turn left} split, obtaining near-perfect
  generalization. We focus in the paper on the more challenging
  \emph{jump} case.} In the \emph{random} split, the training set
includes 80\% of randomly selected distinct SCAN commands, and the
remaining 20\% constitutes the test set. This requires generalization,
as no test command is encountered in testing, but there is no
systematic difference between the commands in the two sets.  In the
\emph{jump} split, the \emph{jump} command is only seen in isolation
during training, and the test set consists of all composite commands
with \emph{jump}. A system able to extract compositional rules (such
as ``\emph{X twice} means to X two times'') should have no problem
generalizing them to a new verb, as in this
split. \newcite{Loula:etal:2018} proposed a set of new SCAN splits,
the most challenging one being the \emph{(primitive) around right}
one.  Here, training data contain examples of \emph{around} and
\emph{right}, but never of the combination of the two. The test set
contains all possible \emph{around right} commands. Loula and
colleagues want to test here ``second-order modification'', as models
must learn here how to compositionally apply the \emph{around}
function to \emph{right}, which is in turn a first-order function
modifying simple action verbs. Examples of commands from the split
used in out experiment are given in Table \ref{table:examples}.
%\mb{Please add table similar to Table 2
%  of Joao's paper, illustrating the 3 splits we use.} \rd{it's table \ref{table:examples} not referenced anywhere yet}

\begin{table*}[t!]
\footnotesize
\centering
\begin{tabular}{| l | l | l |}
%\begin{tabular}{| l | l | p{2cm} |}
\hline \textbf{Split} & \textbf{Train Command} & \textbf{Test Command} \\ \hline
\textit{Random} & random train & random test \\
\hline
\textit{Jump} & jump train & jump test \\
\hline
\textit{Around Right} & around right train & around right test \\
\hline
\end{tabular}
\caption{\label{table:examples} \rd{TODO, I will add proper examples} Training and test examples for the three splits used in our experiments }
\end{table*}


% The SCAN dataset which was introduced in \cite{Lake:Baroni:2017} tests generalization capabilities of a learning model.
% It is designed as a translation task where a sequence of spatial navigation commands have to be translated into corresponding 
% spatial navigation actions. The commands are natural language sentences generated by a Generative grammar \rd{\dots}


\section{Experimental setup}
\paragraph{Model} We use the fully convolutional encoder-decoder model
of \newcite{gehring:etal:2017} out of the box, using the fairseq 
toolkit.\footnote{\url{https://github.com/pytorch/fairseq}}. The model
uses convolutional filters and Gated Linear Units
\cite{dauphin:etal:2016} along with a multi-step attention mechanism
that connects the encoder and the decoder.  Attention is computed
separately for each encoder layer, and produces weighted sums over
encoder input embeddings and encoder outputs. See the original paper
for further details.

\paragraph{Training} The shift in distribution between training and
test splits makes SCAN unsuitable for validation-set tuning. Instead,
following \newcite{Lake:Baroni:2017} and \newcite{Loula:etal:2018} we
train our models on 100k random samples with replacement from the
training commands. We consider models with different batch sizes (from
25 to 100), learning rates (0.1, 0.01, 0.001), layer dimensionalities
(128, 256, 512), layer number (6 to 10) and convolutional
kernel width (3, 4, 5). For all other hyperparameters, we accept the
recommended/default fairseq settings. We run each configuration with 5
different seeds and report below mean values with standard deviation.
% computes different steps (or computations) before calculating its
% final attention scores at any given timestep, similarily to the
% multi-hop method proposed in \cite{sukhbaatar:etal:2015}.\  In order to
% make our findings comparable with previous results
% \cite{Lake:Baroni:2017,Loula:etal:2018}, we trained our models for one
% epoch using Nesterovâ€™s accelerated gradient algorithm
% \cite{sutskever:etal:2013} with a momentum of 0.99
% \cite{pascanu:etal:2012} and clippied the gradient when it exceeded a
% norm of 0.1.




